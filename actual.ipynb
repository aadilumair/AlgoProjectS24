{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Design and Analysis of Algorithms Semester Project\n",
    "22I-0744    Aadil Umair CS-C\n",
    "22I-0908    Salman Umar CS-C\n",
    "22I-1095    Danish Atif CS-C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "README BEFORE RUNNING\n",
    "- This code takes several days to run on PC due to author's experimentation rules\n",
    "- Therfore, the rules have been updated so that the code completes running in 2-3 hours\n",
    "- The results of Algo 6 and Algo 7 are displayed in the last 2 cells\n",
    "- They show the PS, CS and SR values of each funtion tested with an epsilon value with Algo 6 and Algo 7\n",
    "\n",
    "WHAT THE RESULTS MEAN\n",
    "- PR means peak ratio and is defined as the ratio of all global optima found *by my algorithm* to the *amount that should have been found* \n",
    "- SR means the ratio of *successful runs* to *all runs* for each function\n",
    "- CS means the average number of fitness evaluations per run per function to find all the global optima\n",
    "\n",
    "EXPERIMENTAL SETTINGS AND MY DEVIATIONS\n",
    "- Algo 6 and Algo 7 are encapuslated in several loops\n",
    "- The outermost loop iterates through each function (Normal: *All 20*   My Code: *First 10*)\n",
    "- The next loop iterates through each epsilon in the epsilon set (Normal: *All 5*      My code: *1e-04*)\n",
    "- The next loop runs the function a set number of runs just for numerical accuracy (Normal: *51 runs*     My Code: *1 run*)\n",
    "- The next loop allows the function to run until all global optima are found OR if all global optima are not found then for a maximum number of fitness evaluations as allowed by the CEC2013 library for that function\n",
    "- Within this while loop, Algo 6 or 7 is called to generate a solution set (called population in the code below), the fitness evaluations of that set and number of fitness evaluations it took to execute\n",
    "- Then the CEC2013 library checks the amount of global optima present in the sol set and compares it to the amount that should be present\n",
    "- The remaining PR, SR and CS calculations are trivial to calculate and can be understood by looking at the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cec2013.cec2013 import *\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## MISC HELPER FUNCTIONS\n",
    "\n",
    "#Euclidian Distance\n",
    "def Euclidian_distance(vector1, vector2, dim):\n",
    "    sum_squared_diff = sum((vector1[i] - vector2[i])**2 for i in range(dim))\n",
    "    return math.sqrt(sum_squared_diff)\n",
    "\n",
    "#get FSmax and FSmin of a niche\n",
    "def FSmaxMinOfNiche(niche, f):\n",
    "    FSiList = []\n",
    "    for point in niche:\n",
    "        if point.size==1:\n",
    "            FSiList = np.append(FSiList, f.evaluate(np.array([point])))\n",
    "        else:\n",
    "            FSiList = np.append(FSiList, f.evaluate(np.array(point)))\n",
    "    FSiMax = np.max(FSiList)\n",
    "    FSiMin = np.min(FSiList)\n",
    "\n",
    "    return FSiMax, FSiMin, FSiList\n",
    "\n",
    "#get Delta (eq 4)\n",
    "def getDelta(niche_size, epsilon, xj, niche):\n",
    "    total = np.zeros_like(xj)\n",
    "    for i in range(niche_size):\n",
    "        xi = niche[i]\n",
    "        total += np.abs(xi-xj)/(niche_size - 1)\n",
    "    return total*epsilon\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "######### ALGORITHMS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Algo 1 Clustering for Crowding\n",
    "def crowd(f, population, f_population_size, niche_size, no_of_niches, last_niche_size):\n",
    "   #Step 1 Generate Reference Point\n",
    "   ref_pt = np.empty(f.get_dimension())\n",
    "   for i in range(0, f.get_dimension()):\n",
    "      ref_pt[i] = np.random.uniform(f.get_lbound(i), f.get_ubound(i)) \n",
    "   #Step 1 Calculate distance to Reference Points\n",
    "   distances = np.empty(( f_population_size))\n",
    "   for j in range(0, f_population_size):\n",
    "     distances[j] = Euclidian_distance(ref_pt, population[j], f.get_dimension())\n",
    "   \n",
    "   sorted_indices = np.argsort(distances) # get the sorted indices of distances list\n",
    "\n",
    "   pop = population.copy()\n",
    "\n",
    "   niches = np.empty((0, niche_size, f.get_dimension()))\n",
    "   #Step 2\n",
    "   #Here we are making niches by grouping them based on how close they are to the reference point\n",
    "   index = 0\n",
    "\n",
    "   for i in range(0, no_of_niches - 1):\n",
    "      niche = np.empty((niche_size, f.get_dimension()))\n",
    "      for j in range(0, niche_size):\n",
    "         niche[j] = pop[sorted_indices[index]]\n",
    "         index += 1\n",
    "      niches = np.append(niches, [niche], axis = 0)\n",
    "\n",
    "   # ignoring the last niche because it has a mismatched size\n",
    "   # niche = np.empty((last_niche_size, f.get_dimension()))\n",
    "   # for j in range(0, last_niche_size):\n",
    "   #    niche[j] = pop[sorted_indices[index]]\n",
    "   #    index += 1\n",
    "   # niches = np.append(niches, [niche], axis = 0)\n",
    "\n",
    "   return niches\n",
    "\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Algo 2 Clustering for Crowding based on Fitness Evaluation\n",
    "def crowd_fitness(f, population, f_population_size, niche_size, no_of_niches, last_niche_size, fitness_evals):\n",
    "    # Step 1: Sort fitness evaluations and get sorted indices\n",
    "    sorted_indices = np.argsort(fitness_evals)  # Indices of sorted fitness values\n",
    "\n",
    "    # Step 1.1: Sort the population using the sorted indices\n",
    "    sorted_population = population[sorted_indices]\n",
    "\n",
    "    niches = []  # Holds all the niche arrays created later\n",
    "    index = 0  # Tracks the position in the sorted population\n",
    "\n",
    "    # Step 2: Create niches for all but the last group\n",
    "    for i in range(no_of_niches - 1):\n",
    "        niche = sorted_population[index:index + niche_size]  # Slice the sorted population\n",
    "        niches.append(niche)  # Add the niche to the list\n",
    "        index += niche_size\n",
    "\n",
    "    # Step 3: Handle the last niche with the remaining population\n",
    "    # last_niche = sorted_population[index:index + last_niche_size]\n",
    "    # niches.append(last_niche)\n",
    "\n",
    "    return np.array(niches)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Algo 4 Solution Construction for Ants\n",
    "def SolConAnts(niches_set, niche_size, FSmax, FSmin, f, epsilon, eta):\n",
    "\n",
    "    F_const = np.random.rand()\n",
    "\n",
    "    #Step 1\n",
    "    for niche in niches_set:\n",
    "        #Step 1.1\n",
    "        FSimax, FSimin, FSiList = FSmaxMinOfNiche(niche, f)\n",
    "        #Step 1.2 \n",
    "        \n",
    "        sigma = 0.1 + 0.3 * np.exp(- (FSimax - FSimin) / (FSmax - FSmin + eta))\n",
    "        #Step 1.3\n",
    "        #rank of the solution sorted in descending order according to fitness values\n",
    "        ranks = np.argsort(np.argsort(-np.array(FSiList))) + 1\n",
    "\n",
    "        #equation 2\n",
    "        weights = np.array([\n",
    "            (1 / (sigma * np.sqrt(2 * np.pi) * niche_size)) * np.exp(-((rank - 1) ** 2) / (2 * (sigma ** 2) * niche_size ** 2))\n",
    "            for rank in ranks\n",
    "        ])\n",
    "\n",
    "        #equation 1\n",
    "        probabilities = weights / np.sum(weights)\n",
    "\n",
    "        #Step 1.4\n",
    "        sols = []\n",
    "        for i in range(0, niche_size):\n",
    "            #1.4.1\n",
    "            #xj found using roulette wheel selection\n",
    "            cumulative_probs = np.cumsum(probabilities)\n",
    "            j = np.searchsorted(cumulative_probs, np.random.rand())\n",
    "\n",
    "            xj = niche[j]\n",
    "            #1.4.2\n",
    "            if(np.random.rand() < 0.5):\n",
    "                mu = xj\n",
    "            else:\n",
    "                #Get best seed based on which has the best fitness Value\n",
    "                x_seed = niche[np.argmax(FSiList)]\n",
    "                mu = xj + F_const * (x_seed - xj)\n",
    "            #1.4.3\n",
    "            delta = getDelta(niche_size, epsilon, xj, niche)\n",
    "            #1.4.4\n",
    "            sol = np.random.normal(loc=mu, scale=delta) #instead of building our own gaussian/normal dist ftn\n",
    "                                                        #we use numpy's as it's more efficient\n",
    "            sols.append(sol)\n",
    "    return np.array(sols)\n",
    "\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Algo 5\n",
    "def local_search(seeds, fitness_values, std_dev, num_sampled_ind, eta, f):\n",
    "    num_sampled_ind = int(num_sampled_ind)\n",
    "    #step 1\n",
    "    FSEmax = max(fitness_values)\n",
    "    FSEmin = min(fitness_values)\n",
    "    flag = False\n",
    "\n",
    "    #step 2\n",
    "    if(FSEmin<=0):\n",
    "        FSEmax = FSEmax + np.abs(FSEmin) + eta\n",
    "        flag = True\n",
    "    \n",
    "    #step 3\n",
    "    probSet = np.array([])\n",
    "    for i, seed in enumerate(seeds):\n",
    "        if(flag):\n",
    "            prob = (fitness_values[i] + np.abs(FSEmin) + eta)/(FSEmax+np.abs(FSEmin) + eta)\n",
    "        else:\n",
    "            prob = fitness_values[i] / FSEmax\n",
    "        probSet = np.append(probSet, prob)\n",
    "\n",
    "    \n",
    "    #step 4\n",
    "    for i, seed in enumerate(seeds):\n",
    "        if(np.random.rand()<=probSet[i]):\n",
    "            for _ in range(num_sampled_ind):\n",
    "                LSj = seed + np.random.normal(0, std_dev, size=seed.shape)\n",
    "                if(f.evaluate(LSj)>fitness_values[i]):\n",
    "                    seeds[i] = LSj\n",
    "                    fitness_values[i] = f.evaluate(LSj)\n",
    "    return seeds, fitness_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Algo 6\n",
    "def LAMCACO(f, f_population_size, neighbor_size_set, epsilon, eta, local_std_value, num_sampled_ind):\n",
    "    pop_fit_eval_results = np.empty(f_population_size)\n",
    "    NoOfFES = 0\n",
    "    ########### Step 1\n",
    "    # create and init population with random values in range of lower and upper bounds of ftn\n",
    "    population = np.zeros((f_population_size, f.get_dimension()))\n",
    "    for j in range(0, f.get_dimension()):\n",
    "        population[:, j] = np.random.uniform(f.get_lbound(j), f.get_ubound(j), size=f_population_size) \n",
    "\n",
    "    # Compute fitness using function\n",
    "    for i in range(0, f_population_size):\n",
    "        pop_fit_eval_results[i] = f.evaluate(population[i])\n",
    "    NoOfFES += 1\n",
    "    ########### Step 1 END\n",
    "    \n",
    "    ########### Step 2 \n",
    "    FSmax = np.max(pop_fit_eval_results)\n",
    "    FSmin = np.min(pop_fit_eval_results)\n",
    "    ########### Step 2 End\n",
    "  \n",
    "    ########### Step 3\n",
    "    N_nearest = np.random.choice(neighbor_size_set) #randomly select a niche size from the niche size pool  \n",
    "    ########### Step 3 END\n",
    "\n",
    "    ########### Step 4 \n",
    "    niches_num = int(f_population_size / N_nearest) #compute the number of niches\n",
    "\n",
    "    if f_population_size % N_nearest == 0:\n",
    "        last_niche_size = 0\n",
    "    \n",
    "    else: #if the remainder is not 0, then put all the remained individuals as a new niche\n",
    "        niches_num += 1\n",
    "        last_niche_size = f_population_size % N_nearest \n",
    "\n",
    "    niches_set = crowd(f, population, f_population_size, N_nearest, niches_num, last_niche_size)  \n",
    "    ########### Step 4 END\n",
    "\n",
    "    ########### Step 5\n",
    "    sols_set = SolConAnts(niches_set, N_nearest, FSmax, FSmin, f, epsilon, eta)\n",
    "    NoOfFES += N_nearest\n",
    "    ########### Step 5 END\n",
    "\n",
    "    ########### Step 6\n",
    "    #calculating fitness of solutions\n",
    "    sol_fitness_list = np.array([])\n",
    "    for sol in sols_set:\n",
    "        if sol.size==1:\n",
    "            sol_fitness_list = np.append(sol_fitness_list, f.evaluate(np.array([sol])))\n",
    "        else:\n",
    "            sol_fitness_list = np.append(sol_fitness_list, f.evaluate(np.array(sol)))\n",
    "    NoOfFES += 1\n",
    "    # Checking which solution is better\n",
    "    for i, sol in enumerate(sols_set):\n",
    "        # Find the nearest solution in the population\n",
    "        nearest_sol_index = np.argmin(np.linalg.norm(population - sol, axis=1))\n",
    "\n",
    "        # Compare the fitness of the current solution with the nearest solution in the population\n",
    "        if(sol_fitness_list[i] is None):\n",
    "            sol_fitness_list[i] = 0\n",
    "\n",
    "        if sol_fitness_list[i] > pop_fit_eval_results[nearest_sol_index]:\n",
    "            # Update the population with the better solution\n",
    "            population[nearest_sol_index] = sol\n",
    "\n",
    "            # Update the population fitness list\n",
    "            pop_fit_eval_results[nearest_sol_index] = sol_fitness_list[i]\n",
    "    ########### Step 6 END\n",
    "\n",
    "    ########### Step 7\n",
    "    seeds, fitness_values = local_search(population, pop_fit_eval_results, num_sampled_ind ,local_std_value, eta, f)\n",
    "    ########### Step 7 END\n",
    "\n",
    "    return seeds, fitness_values, NoOfFES\n",
    "    ###########Debug`\n",
    "    # print(\"--------------\")\n",
    "    # print(population.shape)\n",
    "    # print(niches_set.shape)\n",
    "    # print(sols_set.shape)\n",
    "    # print(sol_fitness_list.shape)\n",
    "    # print(\"--------------\")\n",
    "    ###########Debug END\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#algo 7 Local Search-Based AMS-ACO (LAMS-ACO) based on fitness ONLY\n",
    "def LAMSACO(f, f_population_size, neighbor_size_set, epsilon, eta, local_std_value, num_sampled_ind):\n",
    "    pop_fit_eval_results = np.empty(f_population_size)\n",
    "    NoOfFES = 0\n",
    "    \n",
    "    ########### Step 1\n",
    "    # Create and initialize the population with random values within function bounds\n",
    "    population = np.zeros((f_population_size, f.get_dimension()))\n",
    "    for j in range(f.get_dimension()):\n",
    "        population[:, j] = np.random.uniform(f.get_lbound(j), f.get_ubound(j), size=f_population_size)\n",
    "\n",
    "    # Compute fitness of the population\n",
    "    for i in range(f_population_size):\n",
    "        pop_fit_eval_results[i] = f.evaluate(population[i])\n",
    "    NoOfFES += f_population_size\n",
    "    ########### Step 1 END\n",
    "\n",
    "    ########### Step 2 \n",
    "    FSmax = np.max(pop_fit_eval_results)\n",
    "    FSmin = np.min(pop_fit_eval_results)\n",
    "    ########### Step 2 END\n",
    "\n",
    "    ########### Step 3\n",
    "    # Randomly select a niche size from the given set\n",
    "    N_nearest = np.random.choice(neighbor_size_set)\n",
    "    ########### Step 3 END\n",
    "\n",
    "    ########### Step 4\n",
    "    # Compute the number of niches\n",
    "    niches_num = int(f_population_size / N_nearest)\n",
    "    last_niche_size = f_population_size % N_nearest\n",
    "\n",
    "    # Adjust the number of niches if the last niche is non-zero\n",
    "    if last_niche_size != 0:\n",
    "        niches_num += 1\n",
    "\n",
    "    # Call the fitness-based niching function\n",
    "    niches_set = crowd_fitness(f, population, f_population_size, N_nearest, niches_num, last_niche_size, pop_fit_eval_results)\n",
    "    ########### Step 4 END\n",
    "\n",
    "    ########### Step 5\n",
    "    # Generate solutions using ant-based solution construction\n",
    "    sols_set = SolConAnts(niches_set, N_nearest, FSmax, FSmin, f, epsilon, eta)\n",
    "    NoOfFES += N_nearest\n",
    "    ########### Step 5 END\n",
    "\n",
    "    ########### Step 6\n",
    "    # Evaluate fitness of solutions\n",
    "    sol_fitness_list = np.array([])\n",
    "    for sol in sols_set:\n",
    "        if sol.size == 1:\n",
    "            sol_fitness_list = np.append(sol_fitness_list, f.evaluate(np.array([sol])))\n",
    "        else:\n",
    "            sol_fitness_list = np.append(sol_fitness_list, f.evaluate(np.array(sol)))\n",
    "    NoOfFES += len(sols_set)\n",
    "\n",
    "    # Compare and update the population with better solutions\n",
    "    for i, sol in enumerate(sols_set):\n",
    "        nearest_sol_index = np.argmin(np.linalg.norm(population - sol, axis=1))\n",
    "        if sol_fitness_list[i] > pop_fit_eval_results[nearest_sol_index]:\n",
    "            population[nearest_sol_index] = sol\n",
    "            pop_fit_eval_results[nearest_sol_index] = sol_fitness_list[i]\n",
    "    ########### Step 6 END\n",
    "\n",
    "    ########### Step 7\n",
    "    # Perform local search to refine solutions\n",
    "    seeds, fitness_values = local_search(population, pop_fit_eval_results, num_sampled_ind, local_std_value, eta, f)\n",
    "    ########### Step 7 END\n",
    "\n",
    "    return seeds, fitness_values, NoOfFES\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting up vars\n",
    "population_size_set = np.array([80,80,80,80,80,100,300,300,300,100]) #the population size setting for each function\n",
    "neighbor_size_set = np.array([2,4,8,12,16,20])#the niche size set\n",
    "                                              #how many crowds should be created for each pop\n",
    "                                              #Denoted as input G in algo 6 and 7\n",
    "funToRun = 10\n",
    "epsilon_set = [1e-4]#[1e-1,1e-2,1e-3,1e-4,1e-5]\n",
    "local_std_value = 1e-4\n",
    "eta = 1e-10\n",
    "num_sampled_ind = 2\n",
    "noOfRuns = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running function: f1 with epsilon: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yn/sz7b_m1n2wg127k9bqyqdxsw0000gn/T/ipykernel_63517/3271661248.py:13: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  pop_fit_eval_results[i] = f.evaluate(population[i])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PR: 0.0    SR: 0.0   CS: 50008.0\n",
      "Running function: f2 with epsilon: 0.0001\n",
      "PR: 3.0    SR: 0.0   CS: 50002.0\n",
      "Running function: f3 with epsilon: 0.0001\n",
      "PR: 1.0    SR: 1.0   CS: 50014.0\n",
      "Running function: f4 with epsilon: 0.0001\n",
      "PR: 0.0    SR: 0.0   CS: 50004.0\n",
      "Running function: f5 with epsilon: 0.0001\n",
      "PR: 0.9693412358074444    SR: 0.0   CS: 50012.0\n",
      "Running function: f6 with epsilon: 0.0001\n",
      "PR: 0.0    SR: 0.0   CS: 200004.0\n",
      "Running function: f7 with epsilon: 0.0001\n",
      "PR: 2.0    SR: 0.0   CS: 200002.0\n",
      "Running function: f8 with epsilon: 0.0001\n",
      "PR: 0.0    SR: 0.0   CS: 400000.0\n",
      "Running function: f9 with epsilon: 0.0001\n",
      "PR: 1.0    SR: 0.0   CS: 400006.0\n",
      "Running function: f10 with epsilon: 0.0001\n",
      "PR: -0.5    SR: 0.0   CS: 200000.0\n"
     ]
    }
   ],
   "source": [
    "#Main for LAMCACO\n",
    "for fun in range(1, funToRun + 1):\n",
    "    f = CEC2013(fun) # building function\n",
    "    f_population_size = population_size_set[fun - 1]\n",
    "    \n",
    "    for epsilon in epsilon_set:\n",
    "        print(f\"Running function: f{fun} with epsilon: {epsilon}\" )\n",
    "        sumOfGlobalOptima = 0\n",
    "        sumOfSucceses = 0\n",
    "        highestGlobalOptima = 0\n",
    "        TotalFESCarriedOut = 0\n",
    "        for run in range(noOfRuns):\n",
    "            NoOfFesi = 0\n",
    "            MaxFesAllowed = f.get_maxfes()\n",
    "            globalOptimaFoundNotTuple = 0\n",
    "\n",
    "            while(NoOfFesi<MaxFesAllowed):\n",
    "                population, fitness_values, NoOfFESL = LAMCACO(f, f_population_size, neighbor_size_set, epsilon, eta, local_std_value, num_sampled_ind)\n",
    "                NoOfFesi += NoOfFESL\n",
    "                \n",
    "                #Store highest number of global optima found in case later iteration has less luck\n",
    "\n",
    "                globalOptimaFound = how_many_goptima(population, f, epsilon)\n",
    "                globalOptimaFoundNotTuple = globalOptimaFound[0]\n",
    "                if(globalOptimaFoundNotTuple > highestGlobalOptima):\n",
    "                    highestGlobalOptima = globalOptimaFoundNotTuple\n",
    "\n",
    "                #if all the global optima has been found, break\n",
    "                if globalOptimaFound == f.get_no_goptima():\n",
    "                    break  \n",
    "            \n",
    "            if(highestGlobalOptima == f.get_no_goptima()):\n",
    "                sumOfSucceses += 1\n",
    "            \n",
    "            sumOfGlobalOptima += highestGlobalOptima\n",
    "            TotalFESCarriedOut += NoOfFesi  \n",
    "\n",
    "        PR = sumOfGlobalOptima/(f.get_fitness_goptima()*noOfRuns)\n",
    "        SR = sumOfSucceses/noOfRuns\n",
    "        CS = NoOfFesi/noOfRuns\n",
    "        print(f\"PR: {PR}    SR: {SR}   CS: {CS}\")    \n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running function: f1 with epsilon: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yn/sz7b_m1n2wg127k9bqyqdxsw0000gn/T/ipykernel_63517/2830909127.py:14: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  pop_fit_eval_results[i] = f.evaluate(population[i])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PR: 0.0    SR: 0.0   CS: 50032.0\n",
      "Running function: f2 with epsilon: 0.0001\n",
      "PR: 3.0    SR: 0.0   CS: 50100.0\n",
      "Running function: f3 with epsilon: 0.0001\n",
      "PR: 1.0    SR: 1.0   CS: 50012.0\n",
      "Running function: f4 with epsilon: 0.0001\n",
      "PR: 0.0    SR: 0.0   CS: 50008.0\n",
      "Running function: f5 with epsilon: 0.0001\n",
      "PR: 0.9693412358074444    SR: 0.0   CS: 50072.0\n",
      "Running function: f6 with epsilon: 0.0001\n",
      "PR: 0.0    SR: 0.0   CS: 200108.0\n",
      "Running function: f7 with epsilon: 0.0001\n",
      "PR: 1.0    SR: 0.0   CS: 200288.0\n",
      "Running function: f8 with epsilon: 0.0001\n",
      "PR: 0.0    SR: 0.0   CS: 400240.0\n",
      "Running function: f9 with epsilon: 0.0001\n",
      "PR: 0.0    SR: 0.0   CS: 400264.0\n",
      "Running function: f10 with epsilon: 0.0001\n",
      "PR: -0.0    SR: 0.0   CS: 200068.0\n"
     ]
    }
   ],
   "source": [
    "#Main for LAMSACO\n",
    "for fun in range(1, funToRun + 1):\n",
    "    f = CEC2013(fun) # building function\n",
    "    f_population_size = population_size_set[fun - 1]\n",
    "    \n",
    "    for epsilon in epsilon_set:\n",
    "        print(f\"Running function: f{fun} with epsilon: {epsilon}\" )\n",
    "        sumOfGlobalOptima = 0\n",
    "        sumOfSucceses = 0\n",
    "        highestGlobalOptima = 0\n",
    "        TotalFESCarriedOut = 0\n",
    "        for run in range(noOfRuns):\n",
    "            NoOfFesi = 0\n",
    "            MaxFesAllowed = f.get_maxfes()\n",
    "            globalOptimaFoundNotTuple = 0\n",
    "\n",
    "            while(NoOfFesi<MaxFesAllowed):\n",
    "                population, fitness_values, NoOfFESL = LAMSACO(f, f_population_size, neighbor_size_set, epsilon, eta, local_std_value, num_sampled_ind)\n",
    "                NoOfFesi += NoOfFESL\n",
    "                \n",
    "                #Store highest number of global optima found in case later iteration has less luck\n",
    "\n",
    "                globalOptimaFound = how_many_goptima(population, f, epsilon)\n",
    "                globalOptimaFoundNotTuple = globalOptimaFound[0]\n",
    "                if(globalOptimaFoundNotTuple > highestGlobalOptima):\n",
    "                    highestGlobalOptima = globalOptimaFoundNotTuple\n",
    "\n",
    "                #if all the global optima has been found, break\n",
    "                if globalOptimaFound == f.get_no_goptima():\n",
    "                    break  \n",
    "            \n",
    "            if(highestGlobalOptima == f.get_no_goptima()):\n",
    "                sumOfSucceses += 1\n",
    "            \n",
    "            sumOfGlobalOptima += highestGlobalOptima\n",
    "            TotalFESCarriedOut += NoOfFesi  \n",
    "\n",
    "        PR = sumOfGlobalOptima/(f.get_fitness_goptima()*noOfRuns)\n",
    "        SR = sumOfSucceses/noOfRuns\n",
    "        CS = NoOfFesi/noOfRuns\n",
    "        print(f\"PR: {PR}    SR: {SR}   CS: {CS}\")    \n",
    "\n",
    "        \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
